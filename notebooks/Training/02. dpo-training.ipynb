{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install trl unsloth comet-ml>=3.43.2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-22T01:00:18.238832Z","iopub.execute_input":"2025-07-22T01:00:18.239072Z","iopub.status.idle":"2025-07-22T01:03:36.941234Z","shell.execute_reply.started":"2025-07-22T01:00:18.239046Z","shell.execute_reply":"2025-07-22T01:03:36.940463Z"}},"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.1 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nfastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from unsloth import PatchDPOTrainer\n\nPatchDPOTrainer()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T01:03:36.943205Z","iopub.execute_input":"2025-07-22T01:03:36.943444Z","iopub.status.idle":"2025-07-22T01:04:11.961960Z","shell.execute_reply.started":"2025-07-22T01:03:36.943418Z","shell.execute_reply":"2025-07-22T01:04:11.961139Z"}},"outputs":[{"name":"stdout","text":"ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2025-07-22 01:03:45.227151: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753146225.430712      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753146225.493254      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\ncomet_ml is installed but the Comet API Key is not configured. Please set the `COMET_API_KEY` environment variable to enable Comet logging. Check out the documentation for other ways of configuring it: https://www.comet.com/docs/v2/guides/experiment-management/configure-sdk/#set-the-api-key\n","output_type":"stream"},{"name":"stdout","text":"ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport torch\nfrom datasets import load_dataset\nfrom transformers import TrainingArguments, TextStreamer\nfrom unsloth import FastLanguageModel, is_bfloat16_supported\nfrom trl import DPOConfig, DPOTrainer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T01:04:11.962690Z","iopub.execute_input":"2025-07-22T01:04:11.962952Z","iopub.status.idle":"2025-07-22T01:04:11.971056Z","shell.execute_reply.started":"2025-07-22T01:04:11.962928Z","shell.execute_reply":"2025-07-22T01:04:11.970411Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"max_seq_length = 2048\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name=\"SkillRipper/TwinLlama-3.2-3B-Instruct\",\n    max_seq_length=max_seq_length,\n    load_in_4bit=False,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T01:04:11.971642Z","iopub.execute_input":"2025-07-22T01:04:11.971866Z","iopub.status.idle":"2025-07-22T01:04:40.380805Z","shell.execute_reply.started":"2025-07-22T01:04:11.971851Z","shell.execute_reply":"2025-07-22T01:04:40.380207Z"}},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2025.7.6: Fast Llama patching. Transformers: 4.52.4.\n   \\\\   /|    Tesla P100-PCIE-16GB. Num GPUs = 1. Max memory: 15.888 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 6.0. CUDA Toolkit: 12.6. Triton: 3.3.1\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31.post1. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27a04c9a457445edaaf2ff0d05c304e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4c61504dce94e09b74d53f2e9d22dfa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3510784b1d464804941538b737440855"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fadb721d43d45409f24f01fc77d8324"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74965b280f5c4cf5b47e556127b2431d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e10199f4b56b41778ad37501489b2ae4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e23ceb4a37a24e519f5317c8a5c36030"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1cd6f6d968c472d8d156220927317cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.jinja: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83e34d813a9f4412adaede060703dd6a"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r=16,\n    lora_alpha=16,\n    lora_dropout=0,\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"up_proj\", \"down_proj\", \"o_proj\", \"gate_proj\"],\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T01:04:40.382404Z","iopub.execute_input":"2025-07-22T01:04:40.382637Z","iopub.status.idle":"2025-07-22T01:04:47.547869Z","shell.execute_reply.started":"2025-07-22T01:04:40.382619Z","shell.execute_reply":"2025-07-22T01:04:47.547262Z"}},"outputs":[{"name":"stderr","text":"Unsloth 2025.7.6 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":" dataset = load_dataset(\"SkillRipper/preference-data\", split=\"train\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T01:04:47.548598Z","iopub.execute_input":"2025-07-22T01:04:47.548861Z","iopub.status.idle":"2025-07-22T01:04:49.912505Z","shell.execute_reply.started":"2025-07-22T01:04:47.548827Z","shell.execute_reply":"2025-07-22T01:04:49.911812Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/369 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9fad71d52b44b87a1e911e15d22526e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/242k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21045b73f263464581d969404b46b7f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1110 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0c192329e774a95a6efd723425db1fe"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"alpaca_template = \"\"\"\nBelow is an instruction that describes a task. \nWrite a response that appropriately completes the request.\n ### Instruction:\n {}\n ### Response:\n\"\"\"\n\nEOS_TOKEN = tokenizer.eos_token\n\ndef format_samples(example):\n    example[\"prompt\"] = alpaca_template.format(example[\"prompt\"])\n    example[\"chosen\"] = example['chosen'] + EOS_TOKEN\n    example[\"rejected\"] = example['rejected'] + EOS_TOKEN\n    \n    return {\"prompt\": example[\"prompt\"], \"chosen\": \n\nexample[\"chosen\"], \"rejected\": example[\"rejected\"]}\ndataset = dataset.map(format_samples)\ndataset = dataset.train_test_split(test_size=0.05)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T01:04:49.913427Z","iopub.execute_input":"2025-07-22T01:04:49.913736Z","iopub.status.idle":"2025-07-22T01:04:50.025850Z","shell.execute_reply.started":"2025-07-22T01:04:49.913705Z","shell.execute_reply":"2025-07-22T01:04:50.025112Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1110 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e9d71ca4fd943f780dc5837b37572e4"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"trainer = DPOTrainer(\n    model=model,\n    ref_model=None,\n    tokenizer=tokenizer,\n    beta=0.5,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    max_length=max_seq_length//2,\n    max_prompt_length=max_seq_length//2,\n    args=DPOConfig(\n        learning_rate=2e-6,\n        lr_scheduler_type=\"linear\",\n        per_device_train_batch_size=2,\n        per_device_eval_batch_size=2,\n        gradient_accumulation_steps=8,\n        num_train_epochs=1,\n        fp16=not is_bfloat16_supported(),\n        bf16=is_bfloat16_supported(),\n        optim=\"adamw_8bit\",\n        weight_decay=0.01,\n        warmup_steps=10,\n        output_dir=\"output\",\n        eval_strategy=\"steps\",\n        eval_steps=0.2,\n        logging_steps=1,\n        report_to=\"none\",\n        seed=0,\n    ),\n )\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T01:04:50.026642Z","iopub.execute_input":"2025-07-22T01:04:50.026925Z","iopub.status.idle":"2025-07-22T01:21:01.849931Z","shell.execute_reply.started":"2025-07-22T01:04:50.026905Z","shell.execute_reply":"2025-07-22T01:21:01.849236Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Extracting prompt in train dataset (num_proc=2):   0%|          | 0/1054 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ebabc0aba9a4f788aebb266c0411cf9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to train dataset (num_proc=2):   0%|          | 0/1054 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e45b5a8146fe4ac3adbeb3bf27c9de14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset (num_proc=2):   0%|          | 0/1054 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2903a6c7ddcb4738bd9ca246602ebfc1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting prompt in eval dataset (num_proc=2):   0%|          | 0/56 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01484a7270ee456691c634377d49b5b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to eval dataset (num_proc=2):   0%|          | 0/56 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d332e9e0be774123ad299b67f21653d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing eval dataset (num_proc=2):   0%|          | 0/56 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e396ca086b714b13b4f2a5705eb23a49"}},"metadata":{}},{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 1,054 | Num Epochs = 1 | Total steps = 66\nO^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 8\n\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 8 x 1) = 16\n \"-____-\"     Trainable parameters = 24,313,856 of 3,237,063,680 (0.75% trained)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [66/66 15:43, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>rewards / chosen</th>\n      <th>rewards / rejected</th>\n      <th>rewards / accuracies</th>\n      <th>rewards / margins</th>\n      <th>logps / chosen</th>\n      <th>logps / rejected</th>\n      <th>logits / chosen</th>\n      <th>logits / rejected</th>\n      <th>eval_logits / chosen</th>\n      <th>eval_logits / rejected</th>\n      <th>nll_loss</th>\n      <th>aux_loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>14</td>\n      <td>0.692200</td>\n      <td>0.690605</td>\n      <td>-0.001360</td>\n      <td>-0.006460</td>\n      <td>0.821429</td>\n      <td>0.005100</td>\n      <td>-138.949600</td>\n      <td>-82.829979</td>\n      <td>-0.321397</td>\n      <td>-0.091277</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>0.686600</td>\n      <td>0.682729</td>\n      <td>-0.006674</td>\n      <td>-0.027737</td>\n      <td>0.803571</td>\n      <td>0.021062</td>\n      <td>-139.002716</td>\n      <td>-83.042732</td>\n      <td>-0.323317</td>\n      <td>-0.093832</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>0.677400</td>\n      <td>0.674293</td>\n      <td>-0.013561</td>\n      <td>-0.052001</td>\n      <td>0.839286</td>\n      <td>0.038440</td>\n      <td>-139.071594</td>\n      <td>-83.285385</td>\n      <td>-0.325163</td>\n      <td>-0.095991</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>0.673100</td>\n      <td>0.669017</td>\n      <td>-0.019273</td>\n      <td>-0.068679</td>\n      <td>0.875000</td>\n      <td>0.049406</td>\n      <td>-139.128708</td>\n      <td>-83.452164</td>\n      <td>-0.326521</td>\n      <td>-0.097750</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n      <td>No Log</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Unsloth: Will smartly offload gradients to save VRAM!\n","output_type":"stream"},{"name":"stderr","text":"comet_ml is installed but the Comet API Key is not configured. Please set the `COMET_API_KEY` environment variable to enable Comet logging. Check out the documentation for other ways of configuring it: https://www.comet.com/docs/v2/guides/experiment-management/configure-sdk/#set-the-api-key\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=66, training_loss=0.6810455114552469, metrics={'train_runtime': 960.0786, 'train_samples_per_second': 1.098, 'train_steps_per_second': 0.069, 'total_flos': 0.0, 'train_loss': 0.6810455114552469, 'epoch': 1.0})"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"FastLanguageModel.for_inference(model)\nmessage = alpaca_template.format(\"Write a paragraph to introduce supervised fine-tuning.\", \"\")\ninputs = tokenizer([message], return_tensors=\"pt\").to(\"cuda\")\ntext_streamer = TextStreamer(tokenizer)\n_ = model.generate(**inputs, streamer=text_streamer, max_new_tokens=256, use_cache=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T01:21:01.850798Z","iopub.execute_input":"2025-07-22T01:21:01.851045Z","iopub.status.idle":"2025-07-22T01:21:06.177685Z","shell.execute_reply.started":"2025-07-22T01:21:01.851023Z","shell.execute_reply":"2025-07-22T01:21:06.176887Z"}},"outputs":[{"name":"stdout","text":"<|begin_of_text|>\nBelow is an instruction that describes a task. \nWrite a response that appropriately completes the request.\n ### Instruction:\n Write a paragraph to introduce supervised fine-tuning.\n ### Response:\n Supervised fine-tuning is a method used to adapt a pre-trained model to a specific task. In this process, the pre-trained model is trained on a labeled dataset to learn the task-specific patterns and relationships. The model learns to recognize and classify the task-specific features, and the trained model is then used for prediction or generation tasks. Supervised fine-tuning is a widely used technique in deep learning, especially for natural language processing tasks.<|eot_id|>\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"model.save_pretrained_merged(\"model\", tokenizer, save_method=\"merged_16bit\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T01:21:06.178504Z","iopub.execute_input":"2025-07-22T01:21:06.178757Z","iopub.status.idle":"2025-07-22T01:21:57.182683Z","shell.execute_reply.started":"2025-07-22T01:21:06.178738Z","shell.execute_reply":"2025-07-22T01:21:57.181968Z"}},"outputs":[{"name":"stdout","text":"Found HuggingFace hub cache directory: /root/.cache/huggingface/hub\nChecking cache directory for required files...\nSuccessfully copied all 2 files from cache to model.\nDownloading safetensors index for SkillRipper/TwinLlama-3.2-3B-Instruct...\n","output_type":"stream"},{"name":"stderr","text":"Unsloth: Merging weights into 16bit: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:38<00:00, 19.29s/it]\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(token=\"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T01:21:57.184403Z","iopub.execute_input":"2025-07-22T01:21:57.184632Z","iopub.status.idle":"2025-07-22T01:21:57.302263Z","shell.execute_reply.started":"2025-07-22T01:21:57.184614Z","shell.execute_reply":"2025-07-22T01:21:57.301608Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"model.push_to_hub_merged(\"SkillRipper/TwinLlama-3.2-3B-DPO\", tokenizer, save_method=\"merged_16bit\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T01:21:57.303291Z","iopub.execute_input":"2025-07-22T01:21:57.303566Z","iopub.status.idle":"2025-07-22T01:24:00.362805Z","shell.execute_reply.started":"2025-07-22T01:21:57.303542Z","shell.execute_reply":"2025-07-22T01:24:00.362014Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a214c41b20247db958aabb284946b4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88e565a0a8d74707970d59bea703a336"}},"metadata":{}},{"name":"stdout","text":"Found HuggingFace hub cache directory: /root/.cache/huggingface/hub\nChecking cache directory for required files...\nSuccessfully copied all 2 files from cache to SkillRipper/TwinLlama-3.2-3B-DPO.\nDownloading safetensors index for SkillRipper/TwinLlama-3.2-3B-Instruct...\n","output_type":"stream"},{"name":"stderr","text":"Unsloth: Merging weights into 16bit:   0%|          | 0/2 [00:00<?, ?it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96b1db1d27be4e61a7ae0548c6d25ab8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d96881985f1447fe873178f071d94299"}},"metadata":{}},{"name":"stderr","text":"Unsloth: Merging weights into 16bit:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [01:08<01:08, 68.83s/it]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7907e8651baa4c22a5a0b319aafc2fc4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a243e3205474a72929676afea531827"}},"metadata":{}},{"name":"stderr","text":"Unsloth: Merging weights into 16bit: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:29<00:00, 44.95s/it]\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}